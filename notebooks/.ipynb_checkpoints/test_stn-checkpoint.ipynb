{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343e3b1-629e-4584-b333-c087b3642b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    " \n",
    "class STN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STN, self).__init__()\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        # 移除fc_loc中第一个nn.Linear的输入尺寸定义\n",
    "        self.fc_loc = None  # 将在forward中动态创建\n",
    " \n",
    "        # 用于空间变换网络的权重和偏置初始化参数\n",
    "        self.fc_loc_output_params = torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float)\n",
    " \n",
    "    def forward(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs_size = xs.size()\n",
    "        # 动态计算全连接层的输入尺寸\n",
    "        fc_input_size = xs_size[1] * xs_size[2] * xs_size[3]\n",
    " \n",
    "        # 根据动态计算的输入尺寸创建fc_loc\n",
    "        if self.fc_loc is None:\n",
    "            self.fc_loc = nn.Sequential(\n",
    "                nn.Linear(fc_input_size, 32),\n",
    "                nn.ReLU(True),\n",
    "                nn.Linear(32, 3 * 2)\n",
    "            )\n",
    "            # 初始化空间变换网络的权重和偏置\n",
    "            self.fc_loc[2].weight.data.zero_()\n",
    "            self.fc_loc[2].bias.data.copy_(self.fc_loc_output_params)\n",
    " \n",
    "        xs = xs.view(-1, fc_input_size)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        grid = F.affine_grid(theta, x.size(), align_corners=True)\n",
    "        x = F.grid_sample(x, grid, align_corners=True)\n",
    "        return x\n",
    " \n",
    " \n",
    "def test_stn(input_size=(1, 1, 32, 32)):\n",
    "    stn = STN()\n",
    "    input_tensor = torch.rand(input_size)\n",
    "    transformed_tensor = stn(input_tensor)\n",
    "    print(transformed_tensor.shape)\n",
    " \n",
    "    input_image = input_tensor.numpy()[0][0]\n",
    "    transformed_image = transformed_tensor.detach().numpy()[0][0]\n",
    " \n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(input_image, cmap='gray')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Transformed Image\")\n",
    "    plt.imshow(transformed_image, cmap='gray')\n",
    "    plt.show()\n",
    " \n",
    " \n",
    "# 测试不同尺寸的输入\n",
    "# test_stn(input_size=(1, 1, 32, 32))\n",
    "test_stn(input_size=(1, 1, 64, 64))\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
